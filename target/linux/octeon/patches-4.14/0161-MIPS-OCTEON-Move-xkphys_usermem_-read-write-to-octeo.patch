From 2f9c94c6f0351fc5274be1188fa7fdd14d54b9ee Mon Sep 17 00:00:00 2001
From: David Daney <david.daney@cavium.com>
Date: Thu, 23 May 2019 16:48:17 +0200
Subject: [PATCH 161/345] MIPS: OCTEON: Move xkphys_usermem_{read,write} to
 octeon-cpu.c

They are needed for all CONFIG_CPU_CAVIUM_OCTEON, so move them out of
setup.c, which is only used in CONFIG_CAVIUM_OCTEON_SOC.

Signed-off-by: David Daney <david.daney@cavium.com>
---
 arch/mips/cavium-octeon/cpu.c   | 143 ++++++++++++++++++++++++++++++
 arch/mips/cavium-octeon/setup.c | 150 --------------------------------
 2 files changed, 143 insertions(+), 150 deletions(-)

diff --git a/arch/mips/cavium-octeon/cpu.c b/arch/mips/cavium-octeon/cpu.c
index 036d56cc4591..07fac2aa8c81 100644
--- a/arch/mips/cavium-octeon/cpu.c
+++ b/arch/mips/cavium-octeon/cpu.c
@@ -20,6 +20,149 @@
 #include <asm/page.h>
 #include <asm/octeon/octeon.h>
 
+/* the caller must hold RCU read lock */
+static int is_task_and_current_same(struct task_struct *t)
+{
+	const struct cred *cred = current_cred(), *tcred;
+
+	tcred = __task_cred(t);
+	if ((__kuid_val(cred->euid) ^ __kuid_val(tcred->suid)) &&
+	    (__kuid_val(cred->euid) ^ __kuid_val(tcred->uid)) &&
+	    (__kuid_val(cred->uid)  ^ __kuid_val(tcred->suid)) &&
+	    (__kuid_val(cred->uid)  ^ __kuid_val(tcred->uid))) {
+		return 0;
+	}
+	return 1;
+}
+
+static void octeon_prepare_arch_switch(struct task_struct *next)
+{
+#if defined(CONFIG_CAVIUM_OCTEON_USER_MEM_PER_PROCESS) || \
+	defined(CONFIG_CAVIUM_OCTEON_USER_IO_PER_PROCESS)
+	struct task_struct *group_leader = next->group_leader;
+	union octeon_cvmemctl cvmmemctl;
+	cvmmemctl.u64 = read_c0_cvmmemctl();
+
+#if defined(CONFIG_CAVIUM_OCTEON_USER_MEM_PER_PROCESS)
+	cvmmemctl.s.xkmemenau = test_tsk_thread_flag(group_leader, TIF_XKPHYS_MEM_EN) ? 1 : 0;
+#endif
+
+#if defined(CONFIG_CAVIUM_OCTEON_USER_IO_PER_PROCESS)
+	cvmmemctl.s.xkioenau = test_tsk_thread_flag(group_leader, TIF_XKPHYS_IO_EN) ? 1 : 0;
+#endif
+	write_c0_cvmmemctl(cvmmemctl.u64);
+#endif
+}
+
+static struct task_struct *xkphys_get_task(pid_t pid)
+{
+	struct task_struct *task, *group_leader;
+
+	rcu_read_lock();
+	task = find_task_by_vpid(pid);
+	if (!task) {
+		read_unlock(&tasklist_lock);
+		return NULL;
+	}
+	group_leader = task->group_leader;
+	get_task_struct(group_leader);
+
+	rcu_read_unlock();
+	return group_leader;
+}
+
+int xkphys_usermem_read(long pid)
+{
+	struct task_struct *task;
+	int io, mem;
+
+	task = xkphys_get_task(pid);
+	if (!task)
+		return -ESRCH;
+#if defined(CONFIG_CAVIUM_OCTEON_USER_IO)
+	io = 1;
+#elif defined(CONFIG_CAVIUM_OCTEON_USER_IO_PER_PROCESS)
+	io = test_tsk_thread_flag(task, TIF_XKPHYS_IO_EN);
+#else
+	io = 0;
+#endif
+
+#if defined(CONFIG_CAVIUM_OCTEON_USER_MEM)
+	mem = 1;
+#elif defined(CONFIG_CAVIUM_OCTEON_USER_MEM_PER_PROCESS)
+	mem = test_tsk_thread_flag(task, TIF_XKPHYS_MEM_EN);
+#else
+	mem = 0;
+#endif
+	put_task_struct(task);
+	return (io ? 2 : 0) | (mem ? 1 : 0);
+}
+
+int xkphys_usermem_write(long pid, int value)
+{
+	struct task_struct *task, *group_leader;
+	int permission_ok = 0;
+
+#if defined(CONFIG_CAVIUM_OCTEON_USER_IO)
+	if ((value & 2) == 0)
+		return -EINVAL;
+#elif !defined(CONFIG_CAVIUM_OCTEON_USER_IO_PER_PROCESS)
+	if (value & 2)
+		return -EINVAL;
+#endif
+#if defined(CONFIG_CAVIUM_OCTEON_USER_MEM)
+	if ((value & 1) == 0)
+		return -EINVAL;
+#elif !defined(CONFIG_CAVIUM_OCTEON_USER_MEM_PER_PROCESS)
+	if (value & 1)
+		return -EINVAL;
+#endif
+
+	task = xkphys_get_task(pid);
+	group_leader = task->group_leader;
+
+	if (!task)
+		return -ESRCH;
+
+	rcu_read_lock();
+	/* Allow XKPHYS disable of other tasks from the current user*/
+	if (value == 0 && is_task_and_current_same(task))
+		permission_ok = 1;
+	rcu_read_unlock();
+
+	if (capable(CAP_SYS_RAWIO))
+		permission_ok = 1;
+
+	if (!permission_ok) {
+		put_task_struct(task);
+		return -EPERM;
+	}
+
+	if (value & 1)
+		set_tsk_thread_flag(group_leader, TIF_XKPHYS_MEM_EN);
+	else
+		clear_tsk_thread_flag(group_leader, TIF_XKPHYS_MEM_EN);
+
+	if (value & 2)
+		set_tsk_thread_flag(group_leader, TIF_XKPHYS_IO_EN);
+	else
+		clear_tsk_thread_flag(group_leader, TIF_XKPHYS_IO_EN);
+
+	preempt_disable();
+
+	/*
+	 * If we are adjusting ourselves, make the change effective
+	 * immediatly.
+	 */
+	if (group_leader == current->group_leader)
+		octeon_prepare_arch_switch(current);
+
+	preempt_enable();
+
+	put_task_struct(task);
+	return 0;
+}
+
 static int cnmips_cu2_call(struct notifier_block *nfb, unsigned long action,
 	void *data)
 {
diff --git a/arch/mips/cavium-octeon/setup.c b/arch/mips/cavium-octeon/setup.c
index 8f52113f7eca..8435581446c7 100644
--- a/arch/mips/cavium-octeon/setup.c
+++ b/arch/mips/cavium-octeon/setup.c
@@ -582,156 +582,6 @@ void octeon_user_io_init(void)
 	write_c0_derraddr1(0);
 }
 
-/*
- * Octeon-specific system calls
- */
-
-/* the caller must hold RCU read lock */
-static int is_task_and_current_same(struct task_struct *t)
-{
-	const struct cred *cred = current_cred(), *tcred;
-
-	tcred = __task_cred(t);
-	if ((__kuid_val(cred->euid) ^ __kuid_val(tcred->suid)) &&
-	    (__kuid_val(cred->euid) ^ __kuid_val(tcred->uid)) &&
-	    (__kuid_val(cred->uid)  ^ __kuid_val(tcred->suid)) &&
-	    (__kuid_val(cred->uid)  ^ __kuid_val(tcred->uid))) {
-		return 0;
-	}
-	return 1;
-}
-
-
-static void octeon_prepare_arch_switch(struct task_struct *next)
-{
-#if defined(CONFIG_CAVIUM_OCTEON_USER_MEM_PER_PROCESS) || \
-	defined(CONFIG_CAVIUM_OCTEON_USER_IO_PER_PROCESS)
-	struct task_struct *group_leader = next->group_leader;
-	union octeon_cvmemctl cvmmemctl;
-
-	cvmmemctl.u64 = read_c0_cvmmemctl();
-
-#if defined(CONFIG_CAVIUM_OCTEON_USER_MEM_PER_PROCESS)
-	cvmmemctl.s.xkmemenau = test_tsk_thread_flag(group_leader, TIF_XKPHYS_MEM_EN) ? 1 : 0;
-#endif
-
-#if defined(CONFIG_CAVIUM_OCTEON_USER_IO_PER_PROCESS)
-	cvmmemctl.s.xkioenau = test_tsk_thread_flag(group_leader, TIF_XKPHYS_IO_EN) ? 1 : 0;
-#endif
-	write_c0_cvmmemctl(cvmmemctl.u64);
-#endif
-}
-
-static struct task_struct *xkphys_get_task(pid_t pid)
-{
-	struct task_struct *task, *group_leader;
-
-	rcu_read_lock();
-	task = find_task_by_vpid(pid);
-	if (!task) {
-		read_unlock(&tasklist_lock);
-		return NULL;
-	}
-	group_leader = task->group_leader;
-	get_task_struct(group_leader);
-
-	rcu_read_unlock();
-	return group_leader;
-}
-
-
-int xkphys_usermem_read(long pid)
-{
-	struct task_struct *task;
-	int io, mem;
-
-	task = xkphys_get_task(pid);
-	if (!task)
-		return -ESRCH;
-#if defined(CONFIG_CAVIUM_OCTEON_USER_IO)
-	io = 1;
-#elif defined(CONFIG_CAVIUM_OCTEON_USER_IO_PER_PROCESS)
-	io = test_tsk_thread_flag(task, TIF_XKPHYS_IO_EN);
-#else
-	io = 0;
-#endif
-
-#if defined(CONFIG_CAVIUM_OCTEON_USER_MEM)
-	mem = 1;
-#elif defined(CONFIG_CAVIUM_OCTEON_USER_MEM_PER_PROCESS)
-	mem = test_tsk_thread_flag(task, TIF_XKPHYS_MEM_EN);
-#else
-	mem = 0;
-#endif
-	put_task_struct(task);
-	return (io ? 2 : 0) | (mem ? 1 : 0);
-}
-
-int xkphys_usermem_write(long pid, int value)
-{
-	struct task_struct *task, *group_leader;
-	int permission_ok = 0;
-
-#if defined(CONFIG_CAVIUM_OCTEON_USER_IO)
-	if ((value & 2) == 0)
-		return -EINVAL;
-#elif !defined(CONFIG_CAVIUM_OCTEON_USER_IO_PER_PROCESS)
-	if (value & 2)
-		return -EINVAL;
-#endif
-#if defined(CONFIG_CAVIUM_OCTEON_USER_MEM)
-	if ((value & 1) == 0)
-		return -EINVAL;
-#elif !defined(CONFIG_CAVIUM_OCTEON_USER_MEM_PER_PROCESS)
-	if (value & 1)
-		return -EINVAL;
-#endif
-
-	task = xkphys_get_task(pid);
-	group_leader = task->group_leader;
-
-	if (!task)
-		return -ESRCH;
-
-	rcu_read_lock();
-	/* Allow XKPHYS disable of other tasks from the current user*/
-	if (value == 0 && is_task_and_current_same(task))
-		permission_ok = 1;
-	rcu_read_unlock();
-
-	if (capable(CAP_SYS_RAWIO))
-		permission_ok = 1;
-
-	if (!permission_ok) {
-		put_task_struct(task);
-		return -EPERM;
-	}
-
-	if (value & 1)
-		set_tsk_thread_flag(group_leader, TIF_XKPHYS_MEM_EN);
-	else
-		clear_tsk_thread_flag(group_leader, TIF_XKPHYS_MEM_EN);
-
-	if (value & 2)
-		set_tsk_thread_flag(group_leader, TIF_XKPHYS_IO_EN);
-	else
-		clear_tsk_thread_flag(group_leader, TIF_XKPHYS_IO_EN);
-
-	preempt_disable();
-
-	/*
-	 * If we are adjusting ourselves, make the change effective
-	 * immediately.
-	 */
-	if (group_leader == current->group_leader)
-		octeon_prepare_arch_switch(current);
-
-	preempt_enable();
-
-	put_task_struct(task);
-	return 0;
-}
-
 /**
  * Early entry point for arch setup
  */
-- 
2.25.1

